{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e14c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Don't generate the __pycache__ folder locally\n",
    "sys.dont_write_bytecode = True \n",
    "# Print exception without the buit-in python warning\n",
    "sys.tracebacklimit = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d420f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a93d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size and number of epochs to use during training\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7db223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths and target image size\n",
    "\n",
    "folder_paths = ['./group_1', './group_2', './group_3']\n",
    "\n",
    "img_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719cac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images and convert labels to integers\n",
    "\n",
    "preprocessed_images, labels = preprocess_images(folder_paths, img_size, batch_size, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7770830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'group_1': 0, 'group_2': 1, 'group_3': 2}\n",
    "\n",
    "labels = np.array([class_dict[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets, and convert labels to one-hot encoding\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "num_classes = len(class_dict)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369966f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input shape and number of classes\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Create the model with the given input shape and number of classes\n",
    "\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "model = create_model(input_shape, num_classes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89297423",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "with tqdm(total=epochs) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        history = model.fit(X_train, y_train, batch_size=batch_size, \n",
    "                            epochs=1, verbose=0, \n",
    "                            validation_data=(X_test, y_test))\n",
    "\n",
    "        train_acc = history.history['accuracy'][0]\n",
    "        val_acc = history.history['val_accuracy'][0]\n",
    "        train_loss = history.history['loss'][0]\n",
    "        val_loss = history.history['val_loss'][0]\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        pbar.set_description(f'Epoch {epoch+1}/{epochs}: Train Accuracy: {train_acc:.4f}, Val Accuracy: {val_acc:.4f}')\n",
    "\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7601b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy over epochs\n",
    "\n",
    "plt.plot(train_acc_list, linewidth = 3)\n",
    "plt.plot(val_acc_list, linewidth = 3)\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss over epochs\n",
    "\n",
    "plt.plot(train_loss_list, linewidth = 3)\n",
    "plt.plot(val_loss_list, linewidth = 3)\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'validation'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba53dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to labels\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_true_labels = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5077d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels, normalize='true')\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, cmap = 'Blues', interpolation = 'None')\n",
    "\n",
    "ax.set_xticks(np.arange(num_classes))\n",
    "ax.set_yticks(np.arange(num_classes))\n",
    "\n",
    "ax.set_xticklabels(class_dict.keys())\n",
    "ax.set_yticklabels(class_dict.keys())\n",
    "\n",
    "ax.set_xlabel('Predicted Class')\n",
    "ax.set_ylabel('True Class')\n",
    "\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        text = ax.text(j, i, format(cm[i, j], '.2f'),\n",
    "                       ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > 0.5 else \"black\")\n",
    "\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdd445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data and print the test accuracy\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Test accuracy:', round(score[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions from probabilities to labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Print performance metrics\n",
    "print()\n",
    "print(f'Test accuracy: {accuracy:.3f}')\n",
    "print(f'Test precision: {precision:.3f}')\n",
    "print(f'Test recall: {recall:.3f}')\n",
    "print(f'Test F1-score: {f1:.3f}')\n",
    "print()\n",
    "print(f'Test confusion matrix:\\n{cm}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6787b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
