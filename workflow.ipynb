{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f5455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import sys\n",
    "# Don't generate the __pycache__ folder locally\n",
    "sys.dont_write_bytecode = True \n",
    "# Print exception without the buit-in python warning\n",
    "sys.tracebacklimit = 0 \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc1ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d27e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images:  24%|█████████▋                               | 141/600 [00:15<00:44, 10.22it/s]Premature end of JPEG file\n",
      "Loading images: 100%|█████████████████████████████████████████| 600/600 [00:58<00:00, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess images and convert labels to integers\n",
    "\n",
    "preprocessed_images, labels = preprocess_images(folder_paths, img_size)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872b4b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string labels to numerical labels\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a22764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|████████████████████████████████| 15000/15000 [00:08<00:00, 1798.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate augmented images for all input images\n",
    "\n",
    "augmented_images, augmented_labels = augment_images(img_size, preprocessed_images, labels, n_augmentations=n_augmentations)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a15ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random image to plot\n",
    "\n",
    "idx = np.random.randint(preprocessed_images.shape[0])\n",
    "\n",
    "# Create a list of images to plot (original + augmented)\n",
    "\n",
    "images = [preprocessed_images[idx]]\n",
    "images.extend(augmented_images[i] for i in range(idx*n_augmentations, (idx+1)*n_augmentations))\n",
    "\n",
    "# Create a list of titles for the subplots\n",
    "\n",
    "titles = ['Original']\n",
    "titles.extend([f\"Augmentation #{i+1}\" for i in range(n_augmentations)])\n",
    "\n",
    "# Plot the images as subplots in a grid\n",
    "\n",
    "num_images = len(images)\n",
    "num_rows = int(np.sqrt(num_images))\n",
    "num_cols = int(np.ceil(num_images / num_rows))\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(8, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < num_images:\n",
    "        ax.imshow(images[i])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(titles[i])\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "# Delete last subplot if empty\n",
    "if num_images < num_rows * num_cols:\n",
    "    fig.delaxes(axes.flat[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Augmentations.png', dpi = 200)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a918b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if each label in the original dataset is equal to the label of its corresponding augmented images\n",
    "\n",
    "for i in range(labels.shape[0]):\n",
    "    label = labels[i]\n",
    "    assert all(augmented_labels[i*n_augmentations:(i+1)*n_augmentations] == label)\n",
    "\n",
    "# Combine the original and augmented images\n",
    "\n",
    "all_images = np.concatenate((preprocessed_images, augmented_images), axis=0)\n",
    "\n",
    "# Combine the original and augmented labels\n",
    "\n",
    "all_labels = np.concatenate((labels, np.repeat(labels, n_augmentations)), axis=0)\n",
    "\n",
    "# Check if the number of images and labels in the combined dataset is equal\n",
    "\n",
    "assert all_images.shape[0] == all_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732e21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets, and convert labels to one-hot encoding\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size=split_percentage, random_state=42)\n",
    "\n",
    "num_classes = len(np.unique(all_labels))\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d804dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = X_train.shape[1:]\n",
    "# model = create_model(input_shape, num_classes, learning_rate)\n",
    "\n",
    "model = new_model(X_train, regularization = regularizationkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f14980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 8)         224       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 64, 8)        32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 16)        1168      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                65568     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,403\n",
      "Trainable params: 72,291\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e56c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5754, Val Acc: 0.5756:   5%|█▏                     | 5/100 [00:36<11:18,  7.14s/it]"
     ]
    }
   ],
   "source": [
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "with tqdm(total=epochs) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=1, verbose=0, validation_data=(X_test, y_test))\n",
    "\n",
    "        train_acc = history.history['accuracy'][0]\n",
    "        val_acc = history.history['val_accuracy'][0]\n",
    "        train_loss = history.history['loss'][0]\n",
    "        val_loss = history.history['val_loss'][0]\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        pbar.set_description(f'Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615627a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to labels\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_true_labels = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9887c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), dpi = 300)\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "axs[0].plot(train_acc_list, linewidth=2)\n",
    "axs[0].plot(val_acc_list, linewidth=2)\n",
    "axs[0].set_title('Model Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].legend(['train', 'validation'], loc='best')\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "axs[1].plot(train_loss_list, linewidth=2)\n",
    "axs[1].plot(val_loss_list, linewidth=2)\n",
    "axs[1].set_title('Model Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend(['train', 'validation'], loc='best')\n",
    "\n",
    "plt.savefig('Result.png', dpi = 200)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9159101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class dictionary\n",
    "class_dict = {0: 'group_1', 1: 'group_2', 2: 'group_3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels, normalize='true')\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, cmap = 'Blues', interpolation = 'None')\n",
    "\n",
    "ax.set_xticks(np.arange(num_classes))\n",
    "ax.set_yticks(np.arange(num_classes))\n",
    "\n",
    "ax.set_xticklabels(class_dict.keys())\n",
    "ax.set_yticklabels(class_dict.keys())\n",
    "\n",
    "ax.set_xlabel('Predicted Class')\n",
    "ax.set_ylabel('True Class')\n",
    "\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        text = ax.text(j, i, format(cm[i, j], '.2f'),\n",
    "                    ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > 0.5 else \"black\")\n",
    "\n",
    "plt.colorbar(im)\n",
    "plt.savefig('confusion_matrix.png', dpi = 200)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions from probabilities to labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Print performance metrics\n",
    "print()\n",
    "print(f'Test accuracy: {accuracy:.3f}')\n",
    "print(f'Test precision: {precision:.3f}')\n",
    "print(f'Test recall: {recall:.3f}')\n",
    "print(f'Test F1-score: {f1:.3f}')\n",
    "print()\n",
    "print(f'Test confusion matrix:\\n{cm}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6664101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
