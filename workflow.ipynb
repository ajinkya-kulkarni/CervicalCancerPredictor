{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416631fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548095bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3bdae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229fa03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Don't generate the __pycache__ folder locally\n",
    "sys.dont_write_bytecode = True \n",
    "# Print exception without the buit-in python warning\n",
    "sys.tracebacklimit = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e073387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d19758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5681f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *\n",
    "\n",
    "from parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef0577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9a34ad8a3346aea548f915a623a833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading images:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess images and convert labels to integers\n",
    "\n",
    "original_images, original_labels = preprocess_images(folder_paths, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets, and convert labels to one-hot encoding\n",
    "\n",
    "X_train, X_test, y_train_str, y_test_str = train_test_split(original_images, original_labels, \n",
    "                                                            test_size=split_percentage, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73978dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string labels to numerical labels\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947afe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "\n",
    "num_classes = len(np.unique(original_labels))\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(label_encoder.transform(y_test_str), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cbafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of augmentations\n",
    "n_augmentations = n_augmentations\n",
    "\n",
    "# Define the image data generator and set the augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Initialize empty arrays to store the augmented images and their labels\n",
    "X_train_augmented = np.zeros((X_train.shape[0] * n_augmentations, X_train.shape[1], \n",
    "                              X_train.shape[2], X_train.shape[3]))\n",
    "y_train_augmented = np.zeros((y_train.shape[0] * n_augmentations, y_train.shape[1]))\n",
    "\n",
    "# Loop over each image in X_train\n",
    "for i in range(X_train.shape[0]):\n",
    "    # Expand the dimensions of the image to make it compatible with the datagen.flow() method\n",
    "    img = np.expand_dims(X_train[i], axis=0)\n",
    "    \n",
    "    # Generate n_augmentations augmented images for the current image\n",
    "    augmented_images = datagen.flow(img, batch_size=n_augmentations, shuffle=False)\n",
    "    \n",
    "    # Store the augmented images in the X_train_augmented array\n",
    "    X_train_augmented[i*n_augmentations:(i+1)*n_augmentations] = augmented_images[0]\n",
    "    \n",
    "    # Get the label of the current image\n",
    "    label = y_train[i]\n",
    "    \n",
    "    # Repeat the label n_augmentations times and store it in the y_train_augmented array\n",
    "    y_train_augmented[i*n_augmentations:(i+1)*n_augmentations] = np.tile(label, (n_augmentations, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the original and augmented images\n",
    "\n",
    "X_train_final = np.concatenate((X_train, X_train_augmented))\n",
    "\n",
    "# Combine the original and augmented labels\n",
    "\n",
    "y_train_final = np.concatenate((y_train, y_train_augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate a random index to select a random image from X_train\n",
    "# random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "# # Get the selected image and its label\n",
    "# selected_image = X_train[random_index]\n",
    "# selected_label = y_train[random_index]\n",
    "\n",
    "# # Create a list of images that includes the selected image and its augmented images\n",
    "# images = [selected_image]\n",
    "# labels = [\"Original Image (Class: {})\".format(np.argmax(selected_label))]\n",
    "\n",
    "# # Loop over each image in X_train_augmented that corresponds to the selected image\n",
    "# for i in range(random_index*n_augmentations, (random_index+1)*n_augmentations):\n",
    "#     # Get the augmented image and its label\n",
    "#     augmented_image = X_train_augmented[i]\n",
    "#     augmented_label = y_train_augmented[i]\n",
    "    \n",
    "#     # Add the augmented image and its label to the list of images\n",
    "#     images.append(augmented_image)\n",
    "#     labels.append(\"Augmented Image {} (Class: {})\".format(i-random_index*n_augmentations+1, np.argmax(augmented_label)))\n",
    "    \n",
    "# # Plot the selected image and its augmented images\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(n_augmentations+1):\n",
    "#     plt.subplot(n_augmentations+1, 1, i+1)\n",
    "#     plt.imshow(images[i])\n",
    "#     plt.title(labels[i])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9107149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear tf backend\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182380cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = X_train.shape[1:]\n",
    "# model = create_model(input_shape, num_classes, learning_rate)\n",
    "\n",
    "model = new_model(X_train_final, regularization = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590bb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "with tqdm(total=epochs) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        history = model.fit(X_train_final, y_train_final, batch_size=batch_size, \n",
    "                            epochs=1, verbose=0, \n",
    "                            validation_data=(X_test, y_test))\n",
    "\n",
    "        train_acc = history.history['accuracy'][0]\n",
    "        val_acc = history.history['val_accuracy'][0]\n",
    "        train_loss = history.history['loss'][0]\n",
    "        val_loss = history.history['val_loss'][0]\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        pbar.set_description(f'Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test data\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to labels\n",
    "\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_true_labels = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa7b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), dpi = 300)\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "axs[0].plot(train_acc_list, linewidth=2)\n",
    "axs[0].plot(val_acc_list, linewidth=2)\n",
    "axs[0].set_title('Model Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].legend(['train', 'validation'], loc='best')\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "axs[1].plot(train_loss_list, linewidth=2)\n",
    "axs[1].plot(val_loss_list, linewidth=2)\n",
    "axs[1].set_title('Model Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend(['train', 'validation'], loc='best')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class dictionary\n",
    "class_dict = {0: 'group_1', 1: 'group_2', 2: 'group_3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels, normalize='true')\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, cmap = 'Blues', interpolation = 'None')\n",
    "\n",
    "ax.set_xticks(np.arange(num_classes))\n",
    "ax.set_yticks(np.arange(num_classes))\n",
    "\n",
    "ax.set_xticklabels(class_dict.keys())\n",
    "ax.set_yticklabels(class_dict.keys())\n",
    "\n",
    "ax.set_xlabel('Predicted Class')\n",
    "ax.set_ylabel('True Class')\n",
    "\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        text = ax.text(j, i, format(cm[i, j], '.2f'),\n",
    "                       ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > 0.5 else \"black\")\n",
    "\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions from probabilities to labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "# Print performance metrics\n",
    "print()\n",
    "print(f'Test accuracy: {accuracy:.3f}')\n",
    "print(f'Test precision: {precision:.3f}')\n",
    "print(f'Test recall: {recall:.3f}')\n",
    "print(f'Test F1-score: {f1:.3f}')\n",
    "print()\n",
    "print(f'Test confusion matrix:\\n{cm}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5455a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
